---
title: Intro to statistics
---

# Relationships between different axes

The relationship between a datapoint's position on different axes (For example, performance in school vs. performance in tertiary, or CTR vs. page load time) can have the following characteristics:
1. **Related** - as the data moves on the one axis, there is a corresponding effect on its position on the other.
2. **Linear** - a fixed 1:x gradient; ie.  \\(y= ax + b\\)
3. **Exact** - the data matches the line exactly, with no noise
4. **Positive or negative** - the relationship is positive if the graph curves up.  ie. the trend of the graph is such that the \\(y\\) value increases as the \\(x\\) value does.

# Plot types

* **Scatter** and **bar** charts relate closely, in that a bar is an aggregation of a scatter where each bar represents ranges of the \\(x\\) axis.
* **Pie** and **histogram** charts relate closely: both are views of the frequency of values in a single-dimensional dataset.

# Probability

**Statistics** and **probability** are opposites: Statistics is the use of data to infer causes, whereas probability is to start with a cause and work out how probable it is based on the available data.

We write probabilities as a likelihood out of 1, using a function \\(P\\). Eg. for a coin flip:
* \\( P(heads) = 0.5 \\)
* \\( P(heads) = 0.5 \\)

This gives rise to a basic law of probability.  The probability of any outcome \\( A \\) is equal to the complement of all the other possible outcomes (ie. is equal to the probability that all the others won't happen):

$$ P(A) = 1 - P(\neg A) $$

# Subsequent outcomes - dependency vs. independency

The probability of getting a given outcome multiple times is the product of the probabilities of those outcomes:
$$ P(heads, heads) = P(heads) \cdot P(heads) $$

So, if you flip a coin multiple times hoping for a particular sequence of outcomes \\( x \\), you get:
$$ P(x) = P(x_1) \cdot P(x_2) \cdot P(x_3) \cdot ... \cdot P(x_n) $$

With coin flips, each flip is independent of the previous flips.  In most cases, though, outcomes are dependent:
* If you have natural aptitude has a probability that depends on your parents having one.
* If you get a high-paying knowledge-work job has a probability that depends on your natural aptitude and your education.
* etc

Each of these things is an event.  The bar notation means "given that".  If the probability of getting a positive covid test is the sum of:
* The probability of having covid multiplied by the probability of the test showing a true positive, and
* The probability of not having covid multiplied by the probability of the test showing a true negative

This can be expressed as 
$$ P(POSITIVE) = P(COVID) \cdot P(POSITIVE|COVID) + P(\neg COVID) \cdot P(POSITIVE|\neg COVID) $$

## Truth tables

Truth tables let you map out each of the possible outcomes of the sequence of events; each outcome is a different combo of outcomes of each event.

Eg. we have a bag with two coins.  One coin is loaded (0.9 - tails; 0.1 heads), while one is fair (0.5, 0.5).

What are the chances of picking a coin at random out of the bag, and then flipping a sequence of heads and then tails?

The truth table looks like this:

| Pick a coin  | Flip 1  | Flip 2  | Overall |
|--------------|---------|---------|---------|
| Fair - 0.5   | H - 0.5 | H - 0.5 | 0.125   |
| Fair - 0.5   | H - 0.5 | T - 0.5 | 0.125   |
| Fair - 0.5   | T - 0.5 | H - 0.5 | 0.125   |
| Fair - 0.5   | T - 0.5 | T - 0.5 | 0.125   |
| Unfair - 0.5 | H - 0.9 | H - 0.9 | 0.405   |
| Unfair - 0.5 | H - 0.9 | T - 0.1 | 0.045   |
| Unfair - 0.5 | T - 0.1 | H - 0.9 | 0.045   |
| Unfair - 0.5 | T - 0.1 | T - 0.1 | 0.005   | 

So, the chances of our scenario is the sum of the rows that match (the ones that have the heads -> tails sequence) = \\( P(heads \| tails) = 0.17 \\).

# Bayes' rule

Bayes' rule is when you have a prior probability that you modify given some evidence from a test, giving a "posterior" probability.

Imagine there is a disease that about 10% of the population have - so the probability of having it is \\( P(D) = 0.1 \\).

Now, if there is a test for that disease that is 90% accurate, and 80% specific, then:
* The chance of getting a positive result (\\( P \\)) if you have the disease is \\( P(P\|D) = 0.9\\).
* The chance of getting a positive result if you don't have the disease is \\( P(P\|\neg D) = 0.2 \\)

If you get a positive result, then the probability of actually having the disease is the probability of getting a positive result assuming you do have the disease, divided by the probability of getting a positive result in general.

This is:

$$ P(D | P) = {
    {
        P(P | D) \cdot P(D)
    } \over {
        P(P | D) \cdot P(D) + P(P | \neg D) \cdot P(\neg D)
    }
}$$

In our case:
$$ P(D | P) = {
    {
        0.9 \cdot 0.1
    } \over {
        0.9 \cdot 0.1 + 0.2 \cdot 0.9
    }
}$$

Which is \\( {0.09} \over {0.09 + 0.18} \\) = 33.3%.
